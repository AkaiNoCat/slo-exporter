groups:
- name: slo-exporter-slo-error-budget-alerts
  rules:

  - alert: ErrorBudgetExhausted
    expr:
            slo:stable_version{enabled!="false"}
            * on(slo_version, slo_domain, namespace) group_right()
            slo:violation_ratio{slo_time_range="4w"}
            / on (slo_class,slo_domain,slo_version,slo_type,namespace) group_left ()
            (
              slo:violation_ratio_threshold - 1
            )
            +1 <= 0
    labels:
      severity: critical
    annotations:
      title: 'Error budget is exhausted.'
      description: '{{$labels.slo_type | title}} error budget for SLO domain "{{$labels.slo_domain}}" was exhausted.'


# SLO burn-rate alerts implementing Multiwindow, Multi-Burn-Rate Alerts (https://landing.google.com/sre/workbook/chapters/alerting-on-slos/)
#
#
# Calculation:
# 1. It uses pre-calculated burn-rates over two time ranges
#   1.1 It is multiplied by `slo:stable_version{enabled!="false"}` to select the current stable enabled slo version
#   1.2 It is compared with a burn-rate threshold selected for the given time range
# 2. Both conditions are joined with an `and` on specified labels
#
# Note:
# 1. Every alert has a long window and a short window. The long window is the important one.
#    The shorter window is supposed to prevent alert firing after an issue has been solved.

# One hour alert
#
# The burn-rate threshold of 13.44 is such that given an average request rate,
# the alert would fire on consuming 2 % of 28-day error budget over the last hour.
#

- name: slo-burn-rate-1h-alerts-critical
  rules:
  - alert: SloOneHourAlert
    expr: (
        slo:burn_rate{slo_time_range="1h"}
        * on(slo_version, slo_domain, namespace) group_left() slo:stable_version{enabled!="false"}
        > 13.44
      )
      and on(percentile, slo_class, slo_domain, slo_type, slo_version, namespace)
      (
        slo:burn_rate{slo_time_range="5m"}
        * on(slo_version, slo_domain, namespace) group_left() slo:stable_version{enabled!="false"}
        > 13.44
      )
    labels:
      severity: critical
      alert_type: high_burnrate
    annotations:
      title: "High {{ $labels.slo_type }} burn-rate in SLO domain {{ $labels.slo_domain }} (last hour)"
      description: "Effective {{ $labels.slo_type }} burn-rate of {{ $labels.slo_domain }}/{{ $labels.slo_class }} in the last hour is {{ printf \"%.1f\" $value }}"
      playbook: on-call/high-burn-rate.md

  # Six hour alert
  #
  # The burn-rate threshold of 5.6 is such that given an average request rate,
  # the alert would fire on consuming 5% of 28-day error budget over the last six hours.

- name: slo-burn-rate-6h-alerts-critical
  rules:
  - alert: SloSixHourAlert
    expr:
      (
        slo:burn_rate{slo_time_range="6h"}
        * on(slo_version, slo_domain, namespace) group_left() slo:stable_version{enabled!="false"}
        > 5.6
      )
      and on(percentile, slo_class, slo_domain, slo_type, slo_version, namespace)
      (
        slo:burn_rate{slo_time_range="30m"}
        * on(slo_version, slo_domain, namespace) group_left() slo:stable_version{enabled!="false"}
        > 5.6
      )
    labels:
      severity: critical
      alert_type: high_burnrate
    annotations:
      title: "High {{ $labels.slo_type }} burn-rate in SLO domain {{ $labels.slo_domain }} (6 hours)"
      description: "Effective {{ $labels.slo_type }} burn-rate of {{ $labels.slo_domain }}/{{ $labels.slo_class }} in the last 6 hours is {{ printf \"%.1f\" $value }}"
      playbook: on-call/high-burn-rate.md

  # One day alert
  #
  # The burn-rate threshold of 2.8 is such that given an average request rate,
  # the alert would fire on consuming 5% of 28-day error budget over the last day.
- name: slo-burn-rate-1d-alerts
  rules:
  - alert: SloOneDayAlert
    expr: (
        slo:burn_rate{slo_time_range="1d"}
        * on(slo_version, slo_domain, namespace) group_left() slo:stable_version{enabled!="false"}
        > 2.8
      )
      and on(percentile, slo_class, slo_domain, slo_type, slo_version, namespace)
      (
        slo:burn_rate{slo_time_range="2h"}
        * on(slo_version, slo_domain, namespace) group_left() slo:stable_version{enabled!="false"}
        > 2.8
      )
    labels:
      severity: warning
      alert_type: high_burnrate
    annotations:
      title: "High {{ $labels.slo_type }} burn-rate in SLO domain {{ $labels.slo_domain }} (24 hours)"
      description: "Effective {{ $labels.slo_type }} burn-rate of {{ $labels.slo_domain }}/{{ $labels.slo_class }} in the last 24 hours is {{ printf \"%.1f\" $value }}"
      playbook: on-call/high-burn-rate.md

  # Three day alert
  #
  # The burn-rate threshold of 1 is such that given an average request rate,
  # the alert would fire on consuming more error budget in the last three days
  # than is allocated for 3 days. (10.7% of the 28-day error budget)
- name: slo-burn-rate-3d-alerts
  rules:
  - alert: SloThreeDaysAlert
    expr:
      (
        slo:burn_rate{slo_time_range="3d"}
        * on(slo_version, slo_domain, namespace) group_left() slo:stable_version{enabled!="false"}
        > 1
      )
      and on(percentile, slo_class, slo_domain, slo_type, slo_version, namespace)
      (
        slo:burn_rate{slo_time_range="6h"}
        * on(slo_version, slo_domain, namespace) group_left() slo:stable_version{enabled!="false"}
        > 1
      )
    labels:
      severity: warning
      alert_type: high_burnrate
    annotations:
      title: "High {{ $labels.slo_type }} burn-rate in SLO domain {{ $labels.slo_domain }} (3 days)"
      description: "Effective {{ $labels.slo_type }} burn-rate of {{ $labels.slo_domain }}/{{ $labels.slo_class }} in the last 3 days is {{ printf \"%.1f\" $value }}"
      playbook: on-call/high-burn-rate.md
